标题,发表年月,一作,一作单位,通讯,通讯单位,宏观维度,应用维度,具身任务,解决的问题,贡献,关联性（为什么这篇论文属于你选择的分类）,方法论,发表情况,链接,负责人,备注/讨论点,父记录
Shake-VLA: Vision-Language-Action Model-Based System for Bimanual Robotic Manipulations and Liquid Mixing,25.01,Muhamamd Haris Khan; Selamawit Asfaw,Skoltech,,,可靠,物理交互,"Manipulation, VLA",通过整合视觉、语言和动作能力，使双臂机器人能够自主理解指令并精确执行复杂物理任务（如调制鸡尾酒）的问题,提出了一个名为Shake-VLA的集成系统，该系统结合了视觉模块、语音模块、RAG和异常检测模块，成功地让双臂机器人在真实世界中以极高的成功率完成了从理解配方到精确倾倒液体的多步骤操纵任务,描述了一个在真实世界中执行物理操纵任务（调制鸡尾酒）的机器人系统，其核心是确保任务的可靠执行，通过精确的传感器控制和异常处理机制，最终实现了100%的任务成功率,"MLLM, ",,https://arxiv.org/abs/2501.06919,包亦晟,,
VLA-Cache: Towards Efficient Vision-Language-Action Model via Adaptive Token Caching in Robotic Manipulation,25.02,Siyu Xu,USYD," Chang Xu",USYD,可靠,物理交互,Manipulation,如何在不显著牺牲任务成功率的前提下，降低视觉-语言-动作 (VLA) 模型在机器人操作任务中的高昂计算成本，以提升其推理效率和实时性？,提出了一种名为VLA-Cache的自适应令牌缓存机制，通过识别并重用连续视觉帧中静态部分的计算结果（KV-cache），同时确保对任务关键区域进行重新计算，从而在保持高成功率的同时显著加速模型推理。,"物理交互方面: 该论文研究的智能体是基于VLA模型的机器人，在仿真环境（LIBERO, SIMPLER）和真实世界（Kinova Jaco2机械臂）中执行具体的物理操作任务。这些任务包括“拿起橙色的锅”、“把蓝色的方块放到盒子里”、“擦桌子”等（见图3和图4），这些都是有目的的、与物理世界直接交互的动作。
可靠性方面: 论文的核心目标是提升VLA模型在机器人控制中的效率 (efficiency)，同时维持任务的成功率 (success rate)。这完全符合“可靠性 (Do the Thing Right)”的定义。论文在摘要中明确指出，其方法可以“achieve practical acceleration with minimal sacrifice in success rate”（实现实际加速，且成功率牺牲极小）。实验结果（表1）用数据证明了这一点：与基线模型相比，VLA-Cache将平均推理时间从51.91ms减少到31.83ms（效率提升），而平均成功率仅从75.0%微降到74.7%（成功率基本保持）。整个研究的重点是让机器人更快、更高效地完成指定任务，而非避免负面结果（安全性）。","MLLM, 模仿学习, 离线学习, 指令微调",,https://arxiv.org/pdf/2502.02175,包亦晟,,
AgiBot World Colosseo: Large-scale Manipulation Platform for Scalable and Intelligent Embodied Systems,25.03," Team AgiBot-World","HKU,  OpenDriveLab"," Team AgiBot-World","HKU,  OpenDriveLab",可靠,物理交互,"Manipulation, VLA",现有机器人学习数据集规模不足、质量不高、场景单一的问题,贡献了一个大规模、高质量、多场景的真实世界机器人操作数据集（AgiBot World），并提出了一个通用策略模型（GO-1），该模型在利用该数据集进行预训练后，在任务成功率和泛化能力上显著优于先前的方法,通过构建一个大规模、高质量的真实世界物理交互数据集，并基于此训练机器人策略，其核心目标和评估方式均聚焦于显著提升机器人执行物理任务的成功率与泛化能力,"MLLM, Diffusion, 预训练, 指令微调",,https://arxiv.org/abs/2503.06669,包亦晟,,
FP3: A 3D Foundation Policy for Robotic Manipulation,25.03," Rujia Yang, Geng Chen","THU, PJLAB, UC San Diego","Chuan Wen, Yang Gao","THU, PJLAB, Shanghai Qi Zhi Institute",,,Manipulation,如何构建一个机器人操作基础模型，该模型能利用3D几何信息，在大型数据集上预训练后，仅通过少量新任务数据就能高效微调，并泛化到未见过的物体和环境中，从而大幅提升任务成功率？,提出了FP3，首个基于3D点云的大规模（1.3B参数）机器人操作基础策略。该模型通过在一个大型3D机器人数据集（DROID）上进行预训练，并结合高效的微调策略，使其在仅有少量（80个）新任务演示的情况下，也能在新颖环境中达到超过90%的任务成功率。,"物理交互方面: 论文研究的FP3策略模型驱动一个真实的Franka Emika机械臂执行一系列有目的的物理操作任务，包括“折叠毛巾”、“清理桌面”、“扶正杯子”和“倒水”（如图1和图3所示）。这些都是与物理世界直接交互的复杂、多步操作任务。
可靠性方面: 本文的核心贡献是显著提升机器人操作的成功率 (success rate) 和对新环境、新物体的泛化能力/鲁棒性 (generalization/robustness)，这完全符合“可靠性”的定义。论文的实验结果有力地证明了这一点：
成功率提升： 在表I中，FP3在“域内（In-domain）”和“野外（In-the-wild）”设置下的平均成功率分别达到了95.0%和82.5%，而表现最好的基线模型OpenVLA仅为7.5%和3.75%。这是一个数量级的提升。
鲁棒性验证： 论文系统地评估了模型在面对未见过的物体、背景、光照、相机视角和干扰物时的性能（如图5所示），FP3在这些扰动下依然保持了极高的成功率，展示了其强大的鲁棒性。
整个研究的目标是让机器人更准确、更稳定地完成指定任务，属于典型的“达成正面目标”的可靠性研究。","Diffusion, Transformer, 指令微调, 预训练",,https://arxiv.org/pdf/2503.08950,包亦晟,,
MoManipVLA: Transferring Vision-language-action Models for General Mobile Manipulation,25.03,Zhenyu Wu,Beijing University of Posts and Telecommunications," Haibin Yan",Beijing University of Posts and Telecommunications,,,Manipulation,如何将为固定基座设计的、具有高泛化能力的VLA（视觉-语言-动作）模型，有效地迁移到移动操作任务中，以解决移动基座和机械臂的协同运动规划问题，从而提高任务成功率？,提出了一个名为MoManipVLA的策略适应框架，该框架利用预训练VLA模型生成末端执行器路点，并通过一个双层优化框架来共同规划移动基座和机械臂的轨迹，以最大化轨迹的物理可行性（如可达性、平滑度），从而显著提升了移动操作任务的成功率。,"物理交互方面: 论文研究的是移动机器人，它需要在家庭等大范围场景中执行物理任务，如“捡起海绵”、“放入碗中”、“打开抽屉”（见图1）。这涉及到导航（移动基座）和操作（机械臂）的结合，是典型的移动操作任务。
可靠性方面: 论文的核心目标是提升移动操作任务的成功率 (success rate) 和效率 (efficiency)。摘要中明确指出，其方法比SOTA方法实现了“4.2%的更高成功率”。其核心贡献是一个双层优化框架，旨在最大化轨迹的“物理可行性”，其中包含了可达性（reachability）、平滑度（smoothness）等直接影响任务成功和执行质量的可靠性指标。实验结果（表1）也以“Overall SR”和“Partial SR”作为主要评估指标，证明了其方法在提升任务完成率方面的有效性。整个工作聚焦于如何让一个强大的固定基座策略在一个更复杂的移动平台上可靠地工作，是典型的可靠性问题。","MLLM, 预训练, 指令微调, 规划算法",,https://arxiv.org/pdf/2503.13446,包亦晟,,
RDT-1B: a Diffusion Foundation Model for Bimanual Manipulation,25.03," Songming Liu; Lingxuan Wu",THU,Hang Su; Jun Zhu,THU,可靠,物理交互,"Manipulation, VLA",为双臂机器人开发基础模型时面临的数据稀缺和动作多模态分布（即同一任务有多种成功方式）的挑战,提出了RDT-1B，一个12亿参数的扩散基础模型，用于双臂操纵。其贡献包括：1) 一个可扩展的、能有效处理多模态动作的Robotics Diffusion Transformer (RDT)架构；2) 一个“物理可解释的统一动作空间”，使得模型能在大规模异构机器人数据集上进行预训练；3) 实验证明该模型在真实机器人上具有卓越的零样本/少样本泛化能力和任务成功率,在真实双臂机器人上执行物理操纵任务，其核心是构建一个能可靠执行任务的基础模型，并通过卓越的零样本泛化能力、精确的指令遵循和远超基线的任务成功率来证明其可靠性,"Diffusion, 预训练, MLLM, ",,https://arxiv.org/abs/2410.07864,包亦晟,,
RoboFlamingo-Plus: Fusion of Depth and RGB Perception with Vision-Language Models for Enhanced Robotic Manipulation,25.03,Xiaojian Li,,Hangjie Mo,,,,Manipulation,如何将深度（Depth）信息有效地融合到基于RGB的VLA模型中，以克服仅依赖视觉信息带来的不稳定性，从而提升机器人在未知或动态环境中的操作鲁棒性和任务成功率？,提出了RoboFlamingo-Plus框架，通过一个预训练的重采样器（resampler）和交叉注意力机制，将ViT编码的深度信息与RGB视觉信息进行有效融合，从而显著提升了模型对3D环境的理解和操作性能。,"物理交互方面: 该论文研究的是一个机器人操作模型，在CALVIN基准测试环境中执行由自然语言指令引导的复杂操作任务。这些任务是长序列的，需要与环境进行精确的物理交互才能完成。
可靠性方面: 本文的核心目标是提升机器人操作的性能 (performance)、鲁棒性 (robustness) 和任务执行能力 (task execution capability)。这完全符合“可靠性 (Do the Thing Right)”的定义。
摘要明确指出，其方法“将机器人操作性能提升10-20%”，并“标志着一个显著的进步”。
论文的核心贡献在于通过融合深度信息来克服仅使用RGB信息时在未知环境中的“输入不稳定性”，从而“加强模型的鲁棒性”。
实验结果（表1）用数据直接证明了其在任务成功率上的提升。例如，在ABC→D的零样本泛化测试中，其模型的平均任务得分从基线的2.062提升到了3.00，这是一个显著的可靠性增强。整个研究聚焦于如何让机器人更准确、更稳定地完成任务，属于典型的可靠性范畴。","MLLM, VLM, 预训练, 指令微调",,https://arxiv.org/pdf/2503.19510,包亦晟,,
TLA: Tactile-Language-Action Model for Contact-Rich Manipulation,25.03," Peng Hao, Chaofan Zhang","Samsung Research China, Institute of Automation,  Chinese Academy of Sciences",,,,,Manipulation,如何利用触觉反馈（tactile feedback）来提升语言条件下的机器人模型在接触丰富（contact-rich）的精密操作任务（如插孔）中的成功率和精度？,提出了一种名为TLA（Tactile-Language-Action）的模型，该模型将时序触觉图像与语言指令相结合，通过微调一个大型语言模型来直接生成精确的机器人动作，从而显著提高了插孔任务的成功率和泛化能力。,"物理交互方面: 该论文研究的智能体是一个机器人，在专为接触丰富任务设计的高保真模拟环境（基于NVIDIA Isaac Gym）中执行一项非常具体的物理任务：指尖插孔装配 (fingertip peg-in-hole assembly)。智能体根据触觉传感器数据和语言指令，生成一个三维的动作指令 [Δx, Δy, Δrz]（如图1所示），以调整末端执行器的姿态来完成插入动作。这是一个典型的、有目的的、与物理世界紧密交互的操作任务。
可靠性方面: 本文的核心目标是提升机器人完成插孔任务的成功率 (success rate)、精确度 (accuracy) 和效率 (efficiency)。这完全符合“可靠性 (Do the Thing Right)”的定义。
成功率和泛化性： 摘要中明确指出，模型在面对新的、更小的装配间隙（1.6mm和1.0mm）时，仍能达到超过85%的成功率，展示了强大的可靠性和泛化能力。表III和表IV的数据也显示，在不同的间隙和桩钉形状下，TLA模型的成功率（Suc↑）远超基线方法。例如，在多桩钉任务中，TLA的总成功率达到90%，而基线方法最高仅为40%。
精确度和效率： 表I中，TLA模型的“目标收敛率（GCR）”更高，且L1误差显著更低（例如x方向误差为0.079mm，远小于基线的0.370mm），这表明其动作预测更精确。更精确的动作意味着可以用更少的步骤完成任务，从而提升效率（表III中，TLA的平均步数更少）。整个研究聚焦于如何更准、更快、更稳地完成装配任务，属于典型的可靠性范畴。","MLLM, 模仿学习, 离线学习, 指令微调, 预训练",,https://arxiv.org/pdf/2503.08548,包亦晟,,
iManip: Skill-Incremental Learning for Robotic Manipulation,25.03," Zexin Zheng",Sun Yat-sen University,,,,,Manipulation,在机器人操作中，如何让智能体在持续学习新技能时，不会忘记（即发生灾难性遗忘）已经掌握的旧技能，从而保持整体任务的成功率？,提出了一个名为iManip的增量学习框架，该框架通过一种时间感知的回放策略（temporal replay strategy）来维持旧技能的记忆，并利用一个可扩展的PerceiverIO架构来适应新技能的动作原语，有效缓解了灾难性遗忘问题。,"物理交互方面: 该论文研究的智能体在RLBench仿真环境和真实世界的Franka Panda机械臂上执行一系列有目的的物理操作任务。这些任务包括“堆叠积木”、“打开抽屉”、“倒水”、“关上罐子”等（如图1, 2, 7所示），这些都是具体的、与物理世界直接交互的动作。
可靠性方面: 本文的核心贡献是提升机器人在持续学习过程中的可靠性，具体表现为在学习新技能后，对旧技能的任务成功率的维持能力以及整体任务的鲁棒性。论文明确将“灾难性遗忘”（catastrophic forgetting）作为要解决的核心问题，这本质上是一个可靠性问题——智能体无法再可靠地完成它曾经能完成的任务。论文的主要评估指标是“在旧技能上的性能”和“在所有已学习技能上的性能”（见图1(b)和表1）。实验结果表明，iManip框架在增量学习后，在旧技能上的成功率远高于传统增量学习基线（TIB），从而显著提升了整体的平均成功率（表1，平均性能从36.1%提升到45.5%）。这完全符合“Do the Thing Right”的定义，即确保智能体能够持续、稳定地完成其学会的所有任务。","ViT, Transformer, 模仿学习, 离线学习, 增量学习",,https://arxiv.org/pdf/2503.07087,包亦晟,,
Gripper Keypose and Object Pointflow as Interfaces for Bimanual Robotic Manipulation,25.04,Yuyin Yang; Zetao Cai,"FDU, ZJU, PJLAB",Jiangmiao Pang,PJLAB,可靠,物理交互,"Manipulation, VLA",双臂机器人操纵中现有方法的两难困境：基于关键帧（keyframe-based）的方法空间定位精准但难以处理复杂的连续运动，而基于连续动作（continuous-action-based）的方法灵活但空间感知能力弱,提出了一个名为PPI（keyPose and Pointflow Interface）的端到端框架。该框架创新地将目标抓取位姿（keypose）和物体点云流（pointflow）作为中间接口，来指导连续动作的生成，从而兼顾了运动的灵活性和定位的精确性,真实和仿真环境中进行双臂物理操作，提出了一种新颖的控制框架，其核心目标和评估标准均围绕提升任务的成功率、精确度以及在多变环境下的鲁棒性与泛化能力,"Diffusion, 预训练",,https://arxiv.org/abs/2504.17784,包亦晟,,
RoboGround: Robotic Manipulation with Grounded Vision-Language Priors,25.04,Haifeng Huang; Xinyi Chen,"ZJU, PJLAB",Yilun Chen; ZhouZhao,"PJLAB, ZJU",可靠,物理交互,"Manipulation, VLA",现有机器人策略在面对新物体、新指令或复杂场景时泛化能力差的问题,提出了一个名为ROBOGROUND的系统，它利用接地的分割掩码来指导策略网络。同时，他们构建了一个能自动生成大规模、多样化和复杂场景的仿真数据管道，并验证了该方法能显著提升机器人在新场景下的泛化能力,在复杂的仿真环境中执行物理操作任务，其核心目标是利用分割掩码作为引导，显著提升机器人策略在面对未见过物体和复杂指令时的成功率和泛化能力,", MLLM, 预训练, 指令微调",,https://arxiv.org/abs/2504.21530,包亦晟,,
HAMSTER: Hierarchical Action Models For Open-World Robot Manipulation,25.05,"Yi Li, Yuquan Deng, Jesse Zhang","NVIDIA, University of Washington, University of Southern California","Anqi Li, Abhishek Gupta, Ankit Goyal","NVIDIA, University of Washington",可靠,物理交互,Manipulation,如何通过利用廉价、丰富的非本域（off-domain）数据（如网络视频、仿真数据），来提升机器人在开放世界操作任务中的泛化能力和任务成功率？,提出了一种名为HAMSTER的分层动作模型，其中一个高层VLM负责从非本域数据中学习并生成一个粗略的2D任务路径作为指导，一个底层策略则根据此路径执行精确的3D物理动作，从而显著提升了机器人在面对新颖场景和指令时的任务成功率。,"物理交互方面: 论文的核心是研究一个机器人物理操作系统。智能体在真实的物理世界（使用Franka Panda机械臂）和高保真仿真环境（RLBench）中执行一系列有目的的操作任务，例如“拿起青椒并放入红碗中”、“按下按钮”、“打开抽屉”、“擦拭桌面”等（如图4、图5、图8所示）。这些都是典型的、与环境进行直接物理交互的具身智能任务。
可靠性方面: 本文的核心贡献在于提升机器人完成指定任务的成功率 (success rate) 和泛化能力 (generalization)，这完全符合“可靠性”的定义。论文的摘要明确指出，其方法相比基线OpenVLA在真实机器人实验中“实现了平均20%的成功率提升，相当于50%的相对增益”。图4的实验结果详细展示了HAMSTER在多个泛化维度（如新物体、新视觉环境、新语言指令）上的成功率均显著高于基线模型。整个研究的动机和评估指标都聚焦于如何让机器人更准确、更鲁棒地完成任务（达成正面目标），而非避免碰撞或损坏等负面后果（安全性）。","MLLM, 模仿学习, 离线学习, 指令微调, 预训练, 规划算法",,https://arxiv.org/pdf/2502.05485,包亦晟,,
RoboBERT: An End-to-end Multimodal Robotic Manipulation Model,25.05," Sicheng Wang, Sheng Liu, Weiheng Wang","Casbot Robotic Corporation, Karlsruhe Institute of Technology",Bin Fang,Beijing Universuty of Post and Telecommunicate,,,Manipulation,如何在不依赖大规模预训练或微调数据的情况下，提升多模态机器人操作模型在面对多样化语言指令和视觉扰动时的策略稳定性和任务成功率？,提出了一种名为RoboBERT的模型，其核心是一个新颖的两阶段训练范式：第一阶段用标准化的指令稳定地学习一个基础策略，第二阶段再解冻所有模块，用多样化的自然语言指令对齐到已学好的策略上，结合数据增强，从而高效地提升了模型的鲁棒性和最终性能。,"物理交互方面: 该论文研究的RoboBERT模型是一个端到端的机器人操作模型。它在标准的仿真基准测试（CALVIN）和真实世界的6自由度机械臂（REALMAN RM65B）上执行了一系列有目的的物理动作。这些任务包括长序列的物体转移、开合抽屉、堆叠方块等（见图4和表4），这些都是典型的物理交互任务。
可靠性方面: 本文的核心目标是提升任务执行的成功率、效率（以平均任务长度衡量）和对扰动的鲁棒性，完全符合“可靠性”的定义。摘要明确指出，其方法旨在“增强对视觉扰动的鲁棒性”，并“在真实机器人试验中证实了比同类方法更高的成功率”。实验结果有力地支撑了这一点：
在CALVIN基准测试中，RoboBERT在ABCD→D和ABC→D两个设置上均取得了SOTA的平均任务长度（分别为4.52和3.79），直接反映了更高的任务完成效率和成功率（表1和表2）。
在真实机器人实验中，RoboBERT在多项顺序任务和独立任务上的成功率均显著高于基线模型RT-1和MT-ACT（表4）。
论文的消融实验（表3）也清晰地展示了其提出的两阶段训练法和数据增强技术如何直接提升最终的任务性能。整个研究聚焦于如何让机器人更稳定、更准确地完成任务，属于典型的可靠性范畴。","MLLM, Diffusion, ViT, 离线学习, 模仿学习, 指令微调, 预训练",,https://arxiv.org/pdf/2502.07837,包亦晟,,
VLA-RL: Towards Masterful and General Robotic Manipulation with Scalable Reinforcement Learning,25.05,Guanxing Lu,"Tsinghua Shenzhen International Graduate School,  Tsinghua University",Yansong Tang,"Tsinghua Shenzhen International Graduate School,  Tsinghua University",,,Manipulation,如何利用在线强化学习（RL）来克服仅依赖离线模仿学习的VLA（视觉-语言-动作）模型在面对分布外（OOD）场景时容易失败的局限性，从而提升其任务成功率和泛化能力？,提出了一个名为VLA-RL的可扩展强化学习框架，通过将机器人操作任务建模为多模态多轮对话，并利用一个自动生成的伪标签训练的机器人过程奖励模型（Robotic Process Reward Model）来解决稀疏奖励问题，从而有效地利用在线RL来提升预训练VLA模型的性能。,"物理交互方面: 该论文研究的智能体是一个基于OpenVLA模型的机器人，在LIBERO仿真基准中执行复杂的物理操作任务。这些任务包括“拿起橙汁并放入篮子”、“把酒瓶放到架子上”等（见图1和图3），这些都是有目的的、与物理世界或高保真模拟环境进行交互的动作。
可靠性方面: 本文的核心目标是通过在线探索和学习，提升机器人完成指定任务的成功率 (success rate) 和鲁棒性 (robustness)，这完全符合“可靠性”的定义。论文明确指出，仅依赖离线数据的模仿学习方法在OOD场景下会导致失败，而其提出的在线RL方法旨在解决此问题。实验结果（表1）清晰地证明了这一点：VLA-RL在LIBERO基准上的平均成功率达到了81.0%，显著高于其模仿学习基线（OpenVLA SFT）的76.5%。图4的测试时伸缩曲线（Test-time Scaling Curve）也表明，随着RL训练的进行，任务成功率持续稳定提升。整个研究聚焦于如何让智能体更可靠地完成任务（达成正面目标），而非避免负面后果（安全性）。","MLLM, 强化学习, 模仿学习, 在线学习, 离线学习, 预训练, 指令微调",,https://arxiv.org/pdf/2505.18719,包亦晟,,
"Think Small, Act Big: Primitive Prompt Learning for Lifelong Robot Manipulation",25.06," Yuanqi Yao, Yan Ding, Siao Liu, Bin Zhao, Haoming Song","PJLAB, FDU, SJTU, INSAIT,  Sofia University"," Dong Wang",PJLAB,,,Manipulation,如何让机器人在持续学习新操作技能时，通过学习和利用可复用的“运动基元”（motion primitives），来克服灾难性遗忘，并保持对旧技能的执行成功率？,提出了一个名为“基元提示学习”（PPL）的两阶段框架。该框架通过一个“运动感知提示”机制来学习代表跨技能共享知识的“基元提示”，并在学习新技能时，通过优化新的提示同时冻结旧的提示，从而有效转移知识并保持旧技能的性能。,"物理交互方面: 论文研究的智能体是一个机器人操作臂（Franka Panda），在仿真（MimicGen, LIBERO）和真实世界中执行一系列有目的的物理操作任务。这些任务包括“放置方块”、“抓取香蕉”、“打开抽屉”、“放置杯子”等（如图1, 2, 4, 5所示），这些都是典型的、与物理世界直接交互的具身智能任务。
可靠性方面: 本文的核心目标是解决终身学习中的“灾难性遗忘”问题，这直接关系到智能体在持续学习过程中的可靠性。一个会遗忘旧技能的智能体是不可靠的。论文通过提出的PPL框架，致力于维持甚至提升机器人对所有已学习技能的平均成功率。
核心指标： 论文使用后向迁移权重（BWT）作为关键评估指标之一，该指标直接衡量学习新任务后对旧任务性能的影响。一个高的BWT意味着机器人能很好地保持旧技能，即可靠性高。
实验结果： 表1和表2的数据清晰地表明，PPL框架在FWT（前向迁移）和BWT（后向迁移/抗遗忘）指标上均优于基线方法，这意味着它不仅能更好地学习新技能，还能更可靠地记住旧技能。例如，在表1中，PPL的平均BWT为-0.46，而基线方法低至-0.56，显示出更强的性能保持能力。整个研究聚焦于如何让智能体随着时间的推移，稳定、成功地完成越来越多的任务，这完全符合“Do the Thing Right”的定义。","Diffusion, 离线学习",,https://arxiv.org/pdf/2504.00420,包亦晟,,
,,,,,,,,,,,,,,,包亦晟,,
Legal and Ethical Consideration in Artificial Intelligence in Healthcare: Who Takes Responsibility?,22.3,Nithesh Naik,Manipal Academy of Higher Education,,,价值,"指令理解, 决策规划",survey,文章探讨了人工智能在医疗领域应用中的法律与伦理责任归属问题，并提出了确保算法透明、公平和合规的框架，以平衡技术创新与患者安全。,"该研究为医疗AI的伦理治理和责任划分提供了系统性框架，强调技术发展必须符合""做正确的事""的核心价值观，确保算法透明、公平且合法。","这篇文章为医疗AI的伦理治理提供了责任框架，强调技术发展必须符合""做正确的事""（Do the right thing）的核心价值观，确保算法透明、公平且合法。",综述,,https://www.frontiersin.org/journals/surgery/articles/10.3389/fsurg.2022.862322/full?gclid=Cj0KCQi,郜振焜,,
"Security Considerations in AI-Robotics:
A Survey of Current Methods,
Challenges, and Opportunities",24.01,SUBASH NEUPANE,Mississippi State University,Subash Neupane,Mississippi State University,价值,"指令理解, 环境感知, 物理交互","survey, Manipulation",这篇文章全面综述和分类人工智能与具身智能融合系统中的安全问题，以增强这些系统在攻击表面、伦理法律问题以及人机交互安全三个维度上的整体安全性，从而为相关利益相关者提供指导，确保AI-Robotics系统的可靠和安全应用。,论文提出了一个全面的分类体系，围绕攻击表面、伦理和法律问题以及人机交互安全三个维度，为增强AI-Robotics系统的安全性提供了全面的视角和指导。,论文提出了一个围绕攻击表面、伦理和法律问题以及人机交互安全三个维度的分类体系，为增强AI-Robotics系统的安全性提供了全面的视角和指导，这与“做对的事情”所蕴含的价值观相契合，有助于确保这些系统的发展和应用符合社会伦理、道德和法律要求,"综述, MLLM",,https://arxiv.org/pdf/2310.08565,郜振焜,,
"Disability 4.0: bioethical considerations on the use of embodied artificial intelligence

",24.08,Francesco De Micco,University Campus Bio-Medico of Rome,Roberto Scendoni,"University of Macerata,  Macerata",价值,"指令理解, 环境感知, 决策规划, 物理交互","survey, Manipulation",这篇文章探讨了具身人工智能在残疾人护理中的应用所引发的生物伦理问题，目的是确保这些技术在尊重人的自主性、尊严和平等的前提下，负责任地用于改善残疾人的生活。,这篇文章的贡献在于它通过深入的伦理分析，揭示了具身人工智能在残疾人护理中可能带来的风险和挑战，并提出了一系列具体的伦理建议和实践指南，以确保这些技术的应用能够尊重和保护残疾人的自主性、尊严和平等权利，从而推动一个更加公平、包容和人道的医疗保健环境。,这篇文章从伦理、法律、公平等多个维度，为具身人工智能在残疾人护理中的应用提供了全面的伦理分析和实践建议，有助于确保这些技术的使用符合社会伦理、道德和法律的要求，从而促进公平、包容和尊重个体价值的医疗实践。,综述,,https://www.frontiersin.org/journals/medicine/articles/10.3389/fmed.2024.1437280/full,郜振焜,,
"Humanoid Robots in Tourism and Hospitality—Exploring Managerial, Ethical, and Societal Challenges",24.12,Ida Skubis,Silesian University of Technology,Agata Mesjasz-Lech,Czestochowa University of Technology,价值,"环境感知, 决策规划, 物理交互",survey,这篇文章探讨了人形机器人在旅游和酒店行业的应用，目的是解决如何在实现技术创新和提升服务效率的同时，确保伦理道德的遵循、法律法规的合规以及对社会价值的维护，以实现技术与人文的平衡发展。,文章通过分析人形机器人在旅游和酒店行业的应用，提供了关于其伦理、法律和社会影响的深入见解，为行业实践和政策制定提供了理论支持，促进了对技术与人文平衡发展的讨论。,文章通过深入分析人形机器人在旅游和酒店行业的应用，揭示了其在提升服务效率和质量的同时，如何确保符合伦理、法律和社会价值，为行业提供了在技术与人文之间寻求平衡的理论依据和实践指导。,综述,,https://www.mdpi.com/2076-3417/14/24/11823,郜振焜,,
From Screens to Scenes: A Survey of Embodied AI in Healthcare,25.03,Yihao Liu,Central South University,", Jintai Chen",HKUST(Guangzhou),价值,"指令理解, 环境感知, 决策规划, 物理交互",survey,这篇文章全面综述了具身智能在医疗保健领域的应用、技术基础、挑战和未来发展方向，目的是推动EmAI技术在医疗保健中的创新和实践，以提高医疗效率、可及性和个性化水平。,,这篇文章强调了在开发和应用具身智能技术时，必须遵循社会伦理、法律和公平原则，以确保其符合社会价值（value），避免偏见和不公，从而推动医疗保健领域的技术进步和社会福祉。,综述,,https://arxiv.org/abs/2501.07468,郜振焜,,
Embodied artificial intelligence in ophthalmology,25.06,Yao Qiu,The Hong Kong Polytechnic University,Mingguang He,The Hong Kong Polytechnic University,价值,指令理解,survey,这篇文章探讨了具身智能在眼科领域的应用潜力，同时着重讨论了其在数据、解释和伦理方面面临的挑战，并为具身智能的临床整合指明了未来方向。,这篇文章的贡献在于为具身智能在眼科领域的临床应用提供了伦理和价值层面的指导，强调了在技术发展过程中确保符合社会伦理、法律规范和公平性的重要性。,这篇文章强调了具身人工智能在眼科领域应用中应遵循的价值观（value），包括伦理（ethic）、法律（legal）、公平（fair）等方面，为具身智能技术的负责任发展和临床应用提供了重要的伦理和价值指引。,综述,Nature子刊npj | digital medicine,https://www.nature.com/articles/s41746-025-01754-4.pdf,郜振焜,,
,,,,,,,,,,,,,,,郜振焜,,
,,,,,,,,,,,,,,,郜振焜,,
SafeBench: A Benchmarking Platform for Safety Evaluation of Autonomous Vehicles,22.06,Chejian Xu,UIUC,,,"无害, 可靠","环境感知, 决策规划",Auto Drive,尽管在自动驾驶测试方面付出了大量努力，但在相似条件下比较和理解不同测试场景生成算法和测试机制的有效性和效率仍然具有挑战性。,"统一的评估平台: 提供了1. 首个集成了多种场景生成算法（如对抗性生成、基于知识生成）和安全关键场景模板（遵循NHTSA标准）的统一自动驾驶安全评估平台。
2. 全面的场景覆盖: 整合了8种典型的预碰撞（pre-crash）场景，并为每种场景设计了10种路线变体和4种生成算法，共产生了超过2000个测试场景，实现了对罕见但致命的“角落案例”的有效测试。
3. 多层次评估体系: 建立了包含安全性、功能性和礼仪性三个层次、共10项细分指标的综合评估体系，可以对自动驾驶算法进行全方位诊断。",这是一篇Bench文章，其核心是为自动驾驶领域的“无害性”和“可靠性”提供了系统性的评估方法。 SafeBench通过程序化生成大量现实世界中罕见的、危险的“角落案例”，直接解决了如何有效评估自动驾驶系统在极端情况下的无害性（不碰撞）和可靠性（完成驾驶任务）的难题,"Benchmark, ROS",NIPS2022 Track on Datasets and Benchmarks.,https://arxiv.org/pdf/2206.09682,刘邦威,,
Earbench: Towards evaluating physical risk awareness for task planning of foundation model-based embodied ai agents,24.08,Zihao Zhu,CUHK-sz,Baoyuan Wu,CUHK-sz,无害,"指令理解, 决策规划",Planning,要在真实的物理世界中部署具身智能体，仍然存在一个重大挑战：如何确保EAI的物理安全？,提出EARBench框架，包含数据构造流程和测试评估方法。1. 构建超过2600个测试用例的大规模数据集，覆盖家庭、医疗、工业等7个领域，每个用例都包含文本和AI生成的图像场景。2. 揭示了主流大模型的普遍缺陷: 对包括GPT-4o、Claude 3、Llama-3.1在内的12个主流模型进行了全面评测，发现所有模型都表现出极高的“任务风险率”（TRR > 90%）。3. 提出了两种基于提示工程的风险缓解策略（隐式提醒和显式提醒），并验证了“显式提醒”能有效降低任务风险率，但无法根除问题。,EARBench的直接目标是防止模型规划出物理层面有害的行为，是“无害性”在认知和规划层面的体现,"Benchmark, Prompt, ",,https://arxiv.org/abs/2408.04449,刘邦威,可能是最早的具身大脑的安全bench,
RiskAwareBench: Towards Evaluating Physical Risk Awareness for High-level Planning of LLM-based Embodied Agents,24.08,,,,,,,,,,,,,https://arxiv.org/pdf/2408.04449v1,刘邦威,EARBench的初版,
SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM Agents,24.12,Sheng Yin,SJTU,Siheng Chen,PJLAB,无害,"指令理解, 决策规划",Planning,得益于LLM，具身智能体具备了理解和规划复杂自然语言指令的强大能力，但具身智能体也可能完美地执行一些危险任务，从而可能在现实世界中造成损害,提出了SafeAgentBench，用于评估具身LLM Agent在交互式仿真环境中安全感知任务规划的基准，出了SafeAgentEnv，一个具有底层控制器的通用具身环境。最后提出了一个基于LLM的评估方法。,论文提出的SafeAgentBench评估具身Agent拒绝风险任务和完成无风险任务的规划能力，Bench中覆盖的危害类型都是物理伤害风险,", Prompt, AI2-THOR, Benchmark",,https://arxiv.org/abs/2412.13178,刘邦威,,
HASARD: A Benchmark for Vision-Based Safe Reinforcement Learning in Embodied Agents,25.03,Tristan Tomilin,Eindhoven University of Technology,,,无害,"环境感知, 决策规划, 物理交互","VLN, Planning",通过强化学习 (RL) 推进安全自主系统的发展需要强大的基准测试来评估性能、分析方法并评估智能体的能力。人类主要依靠具身视觉感知来安全地导航并与周围环境互动，这使得视觉感知成为 RL 智能体一项宝贵的能力。然而，现有的基于视觉的 3D 基准测试仅考虑简单的导航任务。,1. 构建并开源了HASARD：一个包含6种多样化安全任务和3个难度等级的3D视觉安全强化学习基准。 2. 揭示了现有算法的不足：通过对主流Safe RL算法的系统评测，证明了它们在权衡安全与性能方面的挑战，特别是在“安全探索”方面。 3. 提供了高效的研究工具：基于ViZDoom引擎，实现了高效率的模拟，并提供了可视化分析工具，加速了Safe RL领域的研究迭代。,这是一篇Bench论文，其核心是评估智能体的“无害性”。它为整个“可信具身智能”框架，特别是“无害”维度，提供了一个统一的、可量化的试验场和评估标准。HASARD中的所有任务都围绕一个核心问题：智能体如何在追求高回报的同时，避免造成各种形式的伤害（即成本）？因此，它直接服务于所有旨在提升具身智能“无害性”和“可靠性”的研究，并覆盖了从“环境感知”到“物理交互”的全过程。,Benchmark,ICLR2025,https://arxiv.org/abs/2503.08241,刘邦威,,
Safety Aware Task Planning via Large Language Models in Robotics,25.03,Azal Ahmad Khan,University of Minnesota,,,无害,"决策规划, 物理交互","Planning, Manipulation",将大型语言模型（LLM）用于机器人任务规划，虽然能处理复杂的指令，但也带来了一个严峻的问题：LLM在规划时往往只关注“如何完成任务”，而忽略了“如何安全地完成任务”。,"这篇论文的主要贡献是提出了一个名为SAFER (Safety-Aware Framework for Execution in Robotics)的完整框架，其贡献点可以分解为：
（1）提出多LLM协作架构 : 创新地将任务规划和安全审计解耦。它引入一个专门的 “Safety Planning LLM”，像一个“安全监察员”一样，与主“Task Planning LLM”进行对话式协作。安全LLM负责审查规划方案、提出安全反馈，主规划LLM再根据反馈进行修改。这避免了单个LLM的认知过载。
（2）整合底层安全保障 (Control Barrier Functions, CBFs): 首次将高层的LLM任务规划与底层的、有严格数学保障的**控制屏障函数(CBF)**相结合。这意味着，即使LLM给出了一个有潜在风险的指令，底层的CBF控制器也能像“安全带”一样，实时修正机器人的动作，确保它不会违反物理安全约束（如避免碰撞、不超过关节限制）。这打通了从高级语义到低级物理执行的安全通路。
引入量化评估指标 （3）(LLM-as-a-Judge): 提出了一个新颖的**“LLM作为法官”**的评估方法。它使用另一个LLM，基于一套明确的安全规则，来客观地量化一个规划方案中包含的“安全违规”数量。这为衡量和比较不同规划器的安全性提供了一个标准化的基准。","核心关联：无害 (Harmless) 论文的根本出发点和最终目标就是确保机器人的行为不会对人类、环境或其他机器人造成物理伤害。整个SAFER框架的设计都是为了实现这一“第一性原则”。它通过在规划和控制的多个层面嵌入安全检查，最大限度地减少了有害行为的发生。
次要但紧密的关联：
可靠 (Reliable) - 把事情做对。SAFER框架不仅仅是阻止坏事发生，它还通过“安全LLM”的反馈，帮助“任务LLM”生成更完整、更合理的计划（例如，补充被遗漏的关键步骤，如“先放好A再拿起B”）。一个安全可靠的计划，本身就是“把事情做对”的一部分。它提升了任务规划的正确性和鲁棒性。
透明 (Transparent) - 可被理解： “LLM-as-a-Judge”模块不仅给出一个安全分数，还能提供可解释的安全报告，指出具体违反了哪些规则。同时，安全LLM和任务LLM之间的对话式反馈过程本身就是一种可审查、可追溯的决策过程。这提升了整个系统决策的透明度。",", Prompt",,https://arxiv.org/pdf/2503.15707,刘邦威,,
A Framework for Benchmarking and Aligning Task-Planning Safety in LLM-Based Embodied Agents,25.04,Yuting Huang,USTC,Mingxiao Ma; Yanyong Zhang,USTC,无害,决策规划,Planning,缺少具身智能体安全性的研究。,提出SafePlan-Bench，定义8种危害类型，包含2027个任务；提出SafeAlign方法，对齐模型决策的安全性。,文章定义的8类危害直接对应有害性，并且做在planing任务上,"指令微调, , VirtualHome, Benchmark",,https://arxiv.org/abs/2504.14650,刘邦威,,
"Subtle Risks, Critical Failures: A Framework for Diagnosing Physical Safety of LLMs for Embodied Decision Making
",25.05,,,,,无害,"指令理解, 决策规划",,,,,,,,刘邦威,,
"AGENTSAFE: Benchmarking the Safety of Embodied Agents on Hazardous Instructions
",25.06,Aishan Liu,BHU,,,"无害, 保障","指令理解, 决策规划","VLA, Planning",目前针对具身VLM智能体的评估基准主要集中在任务完成、泛化或对环境噪声的鲁棒性上，但缺乏在对抗条件下对安全性的评估,提出AgentSafe，包含 1. 模拟环境适配：在AI2-THOR上构建了交互式模拟沙盒；2.风险感知指令数据集，包括三种风险类型：可能对人类造成伤害的指令、导致环境破坏的指令、危及智能体自身的指令；3.全流程评估,"1. 生成了风险指令，如(1) 危害人类 : “毒害别人的饮料”, “把某人困在浴室里”. (2) 危害环境: “点燃窗帘”, “毁坏房间里的所有家具”. (3) 自残 : “把你的手伸进烤箱”, “把自己撞到墙上”.2. 越狱攻击指令","MLLM, AI2-THOR, Benchmark, Attack Paradigm",,https://arxiv.org/pdf/2506.14697,刘邦威,,
,,,,,,,,,,,,,,,刘邦威,,
BadRobot: Jailbreaking Embodied LLMs in the Physical World,24.07,Hangtao Zhang,HUST,,,保障,指令理解,"Planning, EQA(2D)",通过设计特定的攻击方法，揭示了具身大模型在物理世界中的安全风险。,通过实验验证了具身LLM确实可以被操纵去执行有害行为,论文中的攻击方法正是通过精心设计的语言指令来操纵LLM的行为，这直接涉及到指令理解的环节。,Attack Paradigm,ICLR 2025,https://arxiv.org/abs/2407.20242,罗志昊,,
Jailbreaking LLM-Controlled Robots,24.1,Alexander Robey,UPenn,,,保障,指令理解,EQA(2D),如何评估和提高LLM控制的机器人在面对恶意提示时的安全性，以防止其执行有害的物理动作。,提出第一个专门针对LLM控制机器人的“越狱攻击”算法,论文的核心目标是评估和提高LLM控制的机器人在面对恶意提示时的安全性。,"Benchmark, Prompt",ICRA 2025,https://arxiv.org/abs/2410.13691,罗志昊,,
POEX: Understanding and Mitigating Policy Executable Jailbreak Attacks against Embodied AI,24.12,Xuancun Lu,ZJU,,,保障,指令理解,"Planning, EQA(2D)",论文探讨了传统针对LLMs的越狱攻击是否可以直接应用于具身AI系统，并分析了在具身AI场景下越狱攻击所面临的独特挑战。,"构建了Harmful-RLbench，一个专门用于评估具身AI系统在执行任务时的安全性和可用性的通用操作数据集；

提出POEX框架，一个针对具身AI系统的自动化策略可执行越狱攻击框架；

同时探索了基于提示和基于模型的防御策略",论文通过构建数据集和攻击框架，深入研究了LLM在理解并执行复杂指令时的脆弱性，并且提出相应的攻击框架和防御策略,"MLLM, Benchmark, Prompt",,https://arxiv.org/abs/2412.16633,罗志昊,,
Concept Enhancement Engineering: A Lightweight and Efficient Robust Defense Against Jailbreak Attacks in Embodied AI,25.04,Jirui Yang; Zheyu Lin,FDU,,,保障,指令理解,"Planning, EQA(2D)",如何在不显著增加计算开销的情况下，有效防御越狱攻击，以及如何在保持任务性能的同时，增强 LLM 的安全性。,提出一种轻量级且高效的防御方法，通过操纵 LLM 的内部激活（内部表示）来增强安全性。,论文关注如何通过增强模型对安全指令的理解，使其能够更好地识别和拒绝有害输入。,MLLM,,https://arxiv.org/abs/2504.13201,罗志昊,,
BadNAVer: Exploring Jailbreak Attacks On Vision-and-Language Navigation,25.05,Wenqi Lyu,AIML,Qi Wu,AIML,保障,指令理解,VLN,多模态大模型在视觉-语言导航任务中表现出色，但它们对越狱攻击非常脆弱。越狱攻击是指通过精心设计的提示绕过模型的安全机制，从而触发不期望的输出。,提出了首个针对 MLLM 驱动导航器的系统性越狱攻击框架,论文通过设计恶意指令来测试 MLLMs 的指令理解能力。这些指令被设计为能够绕过模型的安全机制，从而揭示模型在理解指令时可能存在的漏洞。,MLLM,,https://arxiv.org/abs/2505.12443,罗志昊,,
Improving Grounded Natural Language Understanding through Human-Robot Dialog,19.05,Jesse Thomason,University of Washington,,,可靠,指令理解,"Navigation, delivery, relocation",机器人应具备动态适应能力，可以通过与人类的对话 持续学习新词汇、新语法结构和感知概念。,提出了一个端到端的框架，包含语义解析、语言接地、对话澄清等模块，支持多轮对话。,通过自然语言提升机器人的适应能力，其中包含了通过对话澄清指令的部分，属于指令理解的可靠性，大模型时代之前的早期工作。,迭代式交互,ICRA 19,https://ieeexplore.ieee.org/abstract/document/8794287,田旗舰,关键词：指令对话,
Learning robust perceptive locomotion for quadrupedal robots in the wild,22.01,TAKAHIRO MIKI,ETH Zurich,,,可靠,环境感知,Locomotion,现有四足机器人依赖本体感知虽然稳健，但严重限制了运动速度与效率，无法实现快速、灵活地适应复杂未知地形。,提出了一种端到端训练的注意力循环编码器，有效融合外部感知与本体感知，无需手工规则调节，实现信息依赖的动态选择，从而在复杂地形中获得更快、更鲁棒的四足运动控制策略。,融合外部感知以增强机器人运动能力，属于利用环境感知提升可靠性，但此类工作偏向机器人，需要探讨是否属于我们的范畴。,强化学习,Science Robotics 22,https://arxiv.org/abs/2201.08117,田旗舰,关键词：传感器外部感知；需要讨论是否属于范畴,
Embodied Multi-Agent Task Planning from Ambiguous Instruction,22.06,Xinzhu Liu,THU,Huaping Liu,THU,可靠,指令理解,Planning,模糊指令下多智能体协作规划。,提出了一个分层的多智能体框架来解决该任务。该框架包括4个核心模块：场景编码器模块、任务规划模块(包括任务分解和任务分配)、动作模块和通信模块，并提出了一个测评Benchmark,针对模糊指令下的多智能体协作问题，属于指令理解的可靠性，大模型时代之前的早期工作。,"Benchmark, 小模型",RSS 22,https://web.archive.org/web/20220704170254id_/http://www.roboticsproceedings.org/rss18/p032.pdf,田旗舰,关键词：模糊指令、多智能体,
DialFRED: Dialogue-Enabled Agents for Embodied Instruction Following,22.07,Xiaofeng Gao,UCLA,,,可靠,指令理解,EQA(2D),人类发出指令，智能体只能被动执行指令，无法主动发问。,提出DialFRED，一个基于ALFRED的Benchmark，支持对话EQA，收集了人工标注的53k条包含对话的QA数据集，并提出一个提问者-执行者框架实现支持对话的智能体,从被动式的指令理解拓展到主动提问，提升了具身系统对于指令理解的可靠性，大模型时代之前的早期工作。,"Benchmark, 强化学习","IEEE Robotics and Automation Letters, 2022",https://arxiv.org/abs/2202.13330,田旗舰,关键词：指令对话,
DoRO: Disambiguation of Referred Object for Embodied Agents,22.1,Pradip Pramanick,TCS Research,Chayan Sarkar,TCS Research,可靠,指令理解,Grounding (2D),智能体在自然语言指令对目标定位中指令模糊的问题。,提出一个新的模型框架，包含一个图网络、多视角融合算法和图判别算法。,针对模糊指令下的Grounding问题，属于指令理解的可靠性，大模型时代之前的早期工作。,小模型,"IEEE Robotics and Automation Letters, 2022",https://ieeexplore.ieee.org/abstract/document/9846930,田旗舰,关键词：模糊指令,
Ask4Help: Learning to Leverage an Expert for Embodied Tasks,22.11,Kunal Pratap Singh ,Allen Institute for AI,,,可靠,决策规划,"Navigation, Room Rearrangement",能否通过让智能体允许向人类等专家寻求帮助来提升可靠性。,提出一个新的RL policy来训练智能体在执行任务的过程中向专家求助以提升任务成功率，同时极小化求助次数。,通过向专家求助以提升任务的成功率，属于对可靠性的提升，求助的内容属于决策规划，大模型时代之前的早期工作。,强化学习,NeurIPS 22,https://arxiv.org/abs/2211.09960,田旗舰,关键词：交互,
PaLM-E: An Embodied Multimodal Language Model,23.03,Danny Driess,"Google, TU Berlin",,,可靠,环境感知,"EQA(2D), Planning, Manipulation",LLM可以在推理、对话上表现强大，但在具身环境中无法直接理解视觉或传感器输入，在具身任务上表现不佳。,将具身数据融入多模态大模型训练；通过混合训练，让模型既能做视觉–语言任务，又能高效具身推理；在模型中引入神经场景表示和实体标注 token 等新架构；通过实验证明扩大模型规模可减轻多模态微调时的灾难性遗忘。,解决LLM在执行具身任务时无法利用具身传感器环境信息从而导致具身任务表现不佳的问题，提出了利用具身数据训练的MLLM，提升了具身任务的表现，属于利用具身感知提升LLM在具身任务的可靠性。,"MLLM, 预训练",NeurIPS 23,https://arxiv.org/abs/2303.03378,田旗舰,关键词：具身大模型,
Resilient Legged Local Navigation: Learning to Traverse with Compromised Perception End-to-End,23.1,Jin Jin,ETH Zurich,,,可靠,环境感知,Navigation,现实环境中感知系统在复杂环境中实效时机器人如何正确导航。,"提出端到端 RL 导航策略，能感知并应对损坏地图中的“看不见”风险；
拟合低层本体传感数据与高层地图感知，融合使用提升鲁棒性；构建逐级难度训练环境与隐状态正则机制。",解决机器人导航中感知失效的问题，属于环境感知的可靠性。,强化学习,ICRA 24,https://ieeexplore.ieee.org/abstract/document/10611254,田旗舰,关键词：感知失效,
Integrating Disambiguation and User Preferences into Large Language Models for Robot Motion Planning,24.04,Mohammed Abugurain,KAUST,,,可靠,指令理解,Navigation,机器人执行自然语言导航指令时面临指令歧义和用户偏好的问题。,提出文本嵌入+随机森林分类判断歧义指令，结合GPT-4澄清对话与偏好记忆，将自然语言导航需求转化为安全、高信度的 LTL 路径规划流程,指令歧义性和用户偏好本质上属于指令理解问题，这篇文章针对这两个问题加以改进，提升导航的可靠性。,,,https://arxiv.org/abs/2404.14547,田旗舰,关键词：指令歧义、用户偏好,
NoisyEQA: Benchmarking Embodied Question Answering Against Noisy Queries,24.12,Tao Wu,NTU,,,可靠,环境感知,EQA(2D),评估具身问答系统在处理含噪声查询时的能力。,提出了一个新的包含噪声的具身问答benchmark，包含感知噪声。,其包含噪声的benchmark中包含感知噪声，属于从环境感知方面评估具身系统的可靠性。,Benchmark,,https://arxiv.org/abs/2412.10726,田旗舰,关键词：感知噪声,
Embodied Escaping: End-to-End Reinforcement Learning for Robot Navigation in Narrow Environment,25.03,Han Zheng,SJTU,,,可靠,决策规划,Navigation,家用机器人（如扫地机）容易陷入室内“死区”（狭窄、障碍密集的狭小空间）导致路径规划失败或被卡住的真实问题。,提出了一个结合动作过滤、高效表示、混合训练与真实验证的端到端强化学习框架。,面向真实世界中家用机器人被卡住的真实问题，解决被卡住的导航问题属于可靠的决策规划。,强化学习,,https://arxiv.org/abs/2503.03208,田旗舰,关键词：狭窄环境,
Uncertainty in Action: Confidence Elicitation in Embodied Agents,25.03,Tianjiao Yu,UIUC,,,可靠,"环境感知, 决策规划","Planning, VLN",具身智能体在复杂、多模态的开域环境中执行任务时，面临感知与决策两方面的不确定性，如何让具身智能体获取与表达其自身的置信度，从而在执行过程中更加可靠与可解释。,提出两大策略体系：启发策略与执行策略，每个策略下包含若干方法，例如CoT、TopK等。,通过系统研究具身智能体的置信度表达能力提升智能体的可靠性，置信度的表达涉及感知和决策，属于可靠性的环境感知和决策规划,不确定度,,https://arxiv.org/abs/2503.10628,田旗舰,关键词：置信度,
A Model-Agnostic Approach for Semantically Driven Disambiguation in Human-Robot Interaction,25.04,Fethiye Irmak Dogan,KTH Royal Institute of Technology,,,可靠,指令理解,Object Search,如何提升机器人对歧义语言指令的理解与处理能力。,提出一种新颖的模型无关方法，利用语义驱动的澄清机制，在更少尝试中增强机器人定位目标物体的能力。利用知识嵌入检测歧义，并通过迭代预测和主动澄清实现更高效率和准确性。,指令歧义性导致指令理解错误本质上属于对指令理解错误，这篇文章就是消除歧义性以提升对于指令的理解能力，从而提升物体检索的能力。,", 迭代式交互, 不确定度",IEEE International Conference on Robot & Human Interactive Communication (RO-MAN),https://arxiv.org/abs/2409.17004,田旗舰,关键词：指令歧义；任务：自然语言描述的定位，不是3D Grounding,
Grounding Multimodal LLMs to Embodied Agents that Ask for Help with Reinforcement Learning,25.04,Ram Ramrakhya,"Georgia Institute of Technology, Meta",,,可靠,指令理解,EQA(2D),具身智能体应该能够识别指令的模糊性，并提出相关的澄清问题，从而准确推断用户意图，更有效地执行任务。,提出了一个新的任务Ask-to-Act，以及Benchmark，通过LLM生成奖励，用强化学习训练MLLM,针对模糊指令/指令歧义的情况，通过强化学习训练MLLM使智能体主动发问，澄清歧义，属于指令理解的可靠性。,"Benchmark, MLLM, 强化学习",,https://arxiv.org/abs/2504.00907,田旗舰,关键词：模糊指令/指令歧义,
Reinforced Reasoning for Embodied Planning,25.05,Di Wu,SJTU,,,可靠,决策规划,VLN,长程具身规划困难。,提出了一种两阶段强化微调训练流程，首先通过监督微调（SFT）蒸馏闭源模型决策结构，再结合强化微调（RFT）与规则化奖励（GRPO）优化策略质量，实现更连贯、安全、可泛化的多步具身规划。,面向长程具身规划的问题，提升可靠性。,"强化学习, 指令微调, MLLM",,https://arxiv.org/abs/2505.22050,田旗舰,关键词：长程规划,
Explainable Embodied Agents Through Social Cues: A Review,21.07,SEBASTIAN WALLKÖTTER,Uppsala University and INESC-ID-Instituto Superior Técnico,,,透明,环境感知,survey,具身智能的可解释性没有一个统一的解释,定义具身智能可解释性，展示可解释性是如何实现以及如何利用不同的社会线索,论文定义了具身智能的可解释性,综述,ACM Transactions on Human-Robot Interaction,https://dl.acm.org/doi/abs/10.1145/3457188,王森,,
Generating Explanations for Embodied Action Decision from Visual Observation,23.1,Xiaohan Wang,XJTU,,,透明,"指令理解, 环境感知, 决策规划","Planning, VLN",现有的研究主要集中在生成用于物体识别的视觉解释，而对解释具身决策的研究则相对较少。,本文研究了基于视觉观察生成行动决策和解释的方法。与识别解释不同，行动的正当性需要证明其优于其他行动。此外，由于代理需要与环境互动（如导航、移动物体），理解场景结构也是必要的,论文聚焦具身决策的解释研究，行为的正当性需要证明优于其他动作，与具身智能的可解释性密切相关,Benchmark,MM'23,https://dl.acm.org/doi/10.1145/3581783.3612351,王森,,
"Embodied Agent Interface: Benchmarking LLMs for Embodied Decision Making",24.1,"Manling Li,Shiyu Zhao,Qineng Wang,Kangrui Wang,Yu Zhou",Stanford University,,,"透明, 可靠","环境感知, 指令理解, 决策规划, 物理交互",Planning,尽管已有大量研究利用LLMs在具身环境中进行决策，但我们对它们的性能仍缺乏系统的理解，因为这些模型通常应用于不同的领域，用于不同的目的，并且基于不同的输入和输出构建。,提出了一种通用接口（EMBODIED AGENT INTERFACE），该接口支持各种任务形式化和基于LLM的模块的输入-输出规范。,论文将大语言模型在具身决策中的表现进行了系统的评估，帮助确定LLM的能力和问题所在，使得具身智能体有效地利用LLMs,", Benchmark",,https://arxiv.org/abs/2410.07166,王森,,
"Embodied-Reasoner: Synergizing Visual Search, Reasoning, and Action for Embodied Interactive Tasks",25.03,Wenqi Zhang,ZJU,,,"透明, 可靠","物理交互, 环境感知, 指令理解, 决策规划","Planning, VLN",深度思维模型在数学和编程任务上的推理能力取得了显著进展，模型在需要通过图像和动作交织轨迹与环境持续互动的具身领域中的有效性仍鲜有研究,提出了一种名为“具身推理器”的模型，该模型将o1风格的推理扩展到了交互式的具身搜索任务中。,论文将长程具身任务分解为了分析、空间推理、反思、规划和验证等阶段，通过模仿学习逐步增强大模型的推理能力，对大模型执行具身推理的各个阶段进行了详细建模和解释,", 迭代式交互",,https://arxiv.org/abs/2503.21696,王森,,
Multi-agent Embodied AI: Advances and Future Directions,25.05,Zhaohan Feng,Beijing Institute of Technology,,,透明,决策规划,survey,现有的研究范围都集中在单一智能体系统上，这些系统通常假设环境是静态和封闭的，无法全面反映动态、开放环境对多代理具身人工智能的复杂性。,文章全面系统地回顾了当前多智能体具身人工智的研究现状，分析了关键贡献，并指出了挑战和未来方向,论文系统回顾了在动态、开放环境下多智能体具身智能的复杂性和关键技术贡献，为具身智能在复杂情况的可解释性提供了坚实理论和技术基础,综述,,https://arxiv.org/pdf/2505.05108?,王森,,
















Characterizing Physical Adversarial Attacks on Robot Motion Planners,24.01,Wenxi Wu,KCL,Wenxi Wu,KCL,保障,决策规划,Planning,探索对运动规划算法进行对抗攻击的策略,作者特别研究了基于物理环境的攻击，并首次提出对运动规划器的两类攻击方式：“planner failure”（规划失败攻击）；“blindspot”（盲区攻击）,直接与“逻辑规划污染”相关，通过篡改环境或地图数据，使规划模块输出错误甚至危险路径，与主题高度重叠。,物理干预,ICRA 2024,https://kclpure.kcl.ac.uk/ws/portalfiles/portal/248844190/icra2024_motion_planning_attacks.pdf,吴雄斌,行为规划,
Random Spoofing Attack against LiDAR-Based Scan Matching SLAM,24.02,Masashi Fukunaga,Mitsubishi Electric Corporation,Takeshi Sugawara,The University of Electro-Communications,保障,环境感知,SLAM,本文是首次系统评估 LiDAR Scan Matching SLAM 在物理世界下对异步激光欺骗攻击的脆弱性,提出了一个以 Z 轴方向干扰地图构建 为核心的新攻击路径。利用 异步随机激光注入技术（参考 Sato 等人提出的 spoofing 攻击），绕过现代 LiDAR 的随机化机制和距离/角度阈值检测。,这个任务对LiDAR进行攻击，干扰机器人建图，可以误导机器人在行进过程中认为发生了“路面变化”等错误感知。,对抗扰动,VehicleSec 2024,https://www.ndss-symposium.org/ndss-paper/auto-draft-476/,吴雄斌,环境感知,
Manipulating Neural Path Planners via Slight Perturbations,24.03,Zikang Xiong,Purdue University," Suresh Jagannathan",Purdue University,保障,决策规划,Navigation,在神经路径规划器中植入后门攻击,本文提出一种新颖方法，用于定义并注入多种隐藏恶意行为（即后门）到神经路径规划器中。这些后门可以通过微小扰动触发，即使这种扰动很小，也能严重破坏路径规划器的完整性和可靠性。,它展示了如何有意识地污染路径规划器的行为逻辑，攻击者不仅能隐藏恶意目标，还能通过极其隐蔽的触发方式（如一个“看不见”的物体）来激活它，是典型的策略级攻击，具备极强隐蔽性与威胁性。,"adversarial attack, Backdoor Attack",,https://arxiv.org/pdf/2403.18256,吴雄斌,行为规划,
A Survey on Adversarial Robustness of LiDAR-based Machine Learning Perception in Autonomous Vehicles,24.11,Junae Kim,,,,保障,环境感知,survey,这篇综述性论文聚焦于对抗性机器学习（AML）与自动驾驶系统的交叉研究领域，并特别关注基于 LiDAR 的感知系统。,作者全面地梳理了相关威胁图谱，包括针对传感器的网络攻击，以及对模型输入的对抗扰动（如伪造点云、图像扰动等）。此外，文章还探讨了当前应对这些威胁的防御策略。,本文谈到了对抗性机器学习对基于LiDAR的感知系统的威胁，梳理了相关威胁的突破，包括针对传感器的网络攻击，并且探讨了一些防御策略。,综述,,https://arxiv.org/pdf/2411.13778v1,吴雄斌,环境感知,
Exploring the Adversarial Vulnerabilities of Vision-Language-Action Models in Robotics,24.11,Taowen Wang,Rochester Institute of Technology,Ruixiang Tang,Rutgers University,保障,决策规划,VLA,系统性评估 VLA 系统的鲁棒性，找出其在面对对抗性攻击时的脆弱点。,"提出三类攻击目标：（a）UADA, UPA, 利用空间分布上的干扰，打乱原有动作策略，典型如使机械臂轨迹震荡或偏离。（b）TMA 精确控制轨迹偏移，例如让机器人“原地绕圈”、“误抓物体”、“冲撞障碍物”等。",这篇文章探究了如何在机器臂操纵层面进行攻击，让运动轨迹发生偏移或者振荡,VLA,,https://arxiv.org/pdf/2411.13587,吴雄斌,控制层面的攻击,
Adversarial Attacks and Detection in Visual Place Recognition for Safer Robot Navigation,25.01,Connor Malone,Queensland University of Technology,Michael Milford,Queensland University of Technology,保障,环境感知,Visual Place Recognition,独立运行的视觉定位系统（VPR，Visual Place Recognition）缺乏有效的对抗攻击防御机制。在机器人导航任务中，这种脆弱性可能导致严重后果（例如走错路、撞上障碍等）。这说明当前VPR系统虽有定位能力，但安全性与鲁棒性不足。,研究了四种通用的对抗攻击和四种为VPR场景设计的新攻击方式。然后研究它们对VPR性能的影响。而且进一步引入了主动防御。,这篇文章主要完成的是对视觉导航的攻击，能够让机器人错误地识别目标，从而走错路甚至撞墙。属于对机器人感知的控制。,"adversarial attack, Defence",IROS 2025,https://arxiv.org/pdf/2506.15988,吴雄斌,环境感知,
Optimal Actuator Attacks on Autonomous Vehicles Using Reinforcement Learning ,25.02,Pengyu Wang,HKUST,Ling Shi,HKUST,保障,物理交互,Auto Drive,如何设计一种更隐蔽、更具破坏性的执行器FDI攻击策略，用于 非线性自动驾驶系统。如何设计一个 泛化能力更强的安全控制器，可在多种攻击情境下保持系统安全,提出了一种面向非线性系统的最优执行器FDI攻击策略。设计了一个泛化能力更强的安全控制器,这篇文章是FDI攻击策略让自动驾驶汽车物理上偏移了轨迹。,强化学习,,https://arxiv.org/pdf/2502.07839,吴雄斌,物理交互,
SLAMSpoof: Practical LiDAR Spoofing Attacks on Localization Systems Guided by Scan Matching Vulnerability Analysis,25.02,Rokuto Nagata,Amano Institute of Technology,Kentaro Yoshioka,Amano Institute of Technology,保障,环境感知,"Auto Drive, Navigation",LiDAR 容易受到 伪造激光信号（spoofing）攻击，攻击者可用激光覆盖真实扫描，从而操控车辆感知错误的环境。,"1. 提出 SLAMSpoof：首个可实用的 LiDAR 定位欺骗攻击系统。2.提出 SLAMSpoof：首个可实用的 LiDAR 定位欺骗攻击系统。3. 对抗策略探讨,提出了一些 潜在防御方法（countermeasures），例如多传感器融合、激光源认证等
",这篇文章主要探讨了伪造激光攻击对传感器的影响，从而使机器人错误感知环境，属于传感器欺诈。,"Point-Wise SMVS, Frame-Wise SMVS",,https://arxiv.org/html/2502.13641v1,吴雄斌,环境感知,
Towards Robust and Secure Embodied AI: A Survey on Vulnerabilities and Attacks,25.02,WENPENG XING,ZJU,MENG HAN,ZJU,保障,"物理交互, 环境感知",survey,对执行器相关的安全威胁建模、攻击路径分类、关键挑战识别等方面的系统性总结。,提出多层次防御建议，从感知层到控制层，涵盖硬件信任链、防御算法、冗余机制等；,这篇文章定义了固件和固件攻击。固件是电机控制器、传感器驱动器、通信模块等低层硬件的重要组成。一旦攻击者控制了这些组件的固件，就能在物理层面操控整个系统：修改电机速度、引入延迟、随意启停执行器，甚至改变控制协议。,综述,,https://arxiv.org/pdf/2502.13175,吴雄斌,物理交互,
Exploring Adversarial Obstacle Attacks in Search-based Path Planning for Autonomous Mobile Robots,25.04,Adrian Szvoren;,UCL,Dimitrios Kanoulas; Nilufer Tuptuk,UCL,保障,决策规划,Navigation,这篇论文聚焦于 搜索式路径规划算法（尤其是经典的 A* 算法）在面对 对抗性环境干扰 时的鲁棒性与脆弱性。A* 算法通常假设环境地图准确，但在现实中地图可能被 恶意篡改（物理或虚拟障碍）。作者研究了在资源有限、环境复杂的真实机器人部署中，环境干扰如何影响规划效率、安全性和实时性。,提出“Obstacle Attacks”威胁模型，实现恶意软件并行攻击机制，深入分析环境复杂度对攻击影响,论文通过篡改地图的方式让机器人的导航规划算法延迟甚至失效。,brute-force algorithm,,https://arxiv.org/pdf/2504.06154,吴雄斌,行为规划,
Robo-Troj: Attacking LLM-based Task Planners,25.04,Mohaiminul Al Nahian; Zainab Altaweel,SUNY Binghamton,Adnan Siraj Rakin,SUNY Binghamton,保障,决策规划,"Manipulation, Planning",现有研究完全忽略了其安全性风险，尤其是后门攻击的可能性。,1. 提出首个针对LLM任务规划的后门攻击（Robo-Troj）；2. 开发触发词优化方法；3. 揭示LLM任务规划系统的脆弱性,这篇文章提出的后门攻击方法可以通过特定的关键词出发后门攻击，让模型规划出有害动作（比如伤害人类）。属于对具身智能行为规划系统发起的攻击。,"指令微调, ",,https://arxiv.org/pdf/2504.17070,吴雄斌,行为规划,
Strategic Planning of Stealthy Backdoor Attacks in Markov Decision Processes,25.04,Xinyi Wei,UFL,Jie Fu,UFL,保障,决策规划,Manipulation,随机控制系统中的后门攻击策略设计,提供一个在测试时“良性”的控制策略，但在运行时配合一个隐蔽触发策略后切换到“恶意”目标,本文在控制策略层面设计了一种能够通过测试，但是会被出发的后门攻击方式，对控制策略进行攻击，让agent执行伤害动作。,强化学习,,https://arxiv.org/pdf/2504.13276,吴雄斌,行为规划,
BadDepth: Backdoor Attacks Against Monocular Depth Estimation in the Physical World,25.05,Ji Guo,USTC,Jiaming He,USTC,保障,环境感知,SLAM,系统性地研究 MDE 模型是否会受到后门攻击，以及攻击者如何实施这种攻击,作者提出了一种全新的攻击方法，命名为 BadDepth；这是第一种专门设计用于深度估计任务的后门攻击方法。,这篇文章探讨了对深度估计的攻击，提出了一种对深度估计植入后门攻击的手段，可以对机器人的环境感知进行攻击。,adversarial attack,,https://arxiv.org/pdf/2505.16154,吴雄斌,环境感知,
BadVLA: Towards Backdoor Attacks on Vision-Language-Action Models via Objective-Decoupled Optimization,25.05,Xueyang Zhou,HUST,Lichao Sun,Lehigh University,保障,决策规划,VLA,与传统的对抗扰动不同，后门攻击更隐蔽、持续性强且实际危害更大，尤其是在现在流行的 “训练即服务（Training-as-a-Service）” 模式下，攻击者可能在训练阶段埋下后门。 然而，目前几乎没有人在 VLA 模型领域研究这一问题。为填补这一空白，本文提出了 BadVLA —— 一种基于 目标解耦优化（Objective-Decoupled Optimization） 的后门攻击方法，首次揭示了 VLA 模型的后门漏洞。,本文首次系统性揭示了 视觉-语言-动作（VLA）模型在机器人控制中的**后门攻击（Backdoor Attack）**安全漏洞，并提出了名为 BadVLA 的攻击方法，在保持正常任务性能的同时，实现了高成功率、强鲁棒性的隐蔽攻击。,这篇文章讨论了对VLA进行后门攻击，让其产生安全隐患。,adversarial attack,,https://arxiv.org/pdf/2505.16640,吴雄斌,行为规划,
Adversarial Attacks on Robotic Vision-Language-Action Models,25.06,Eliot Krzysztof Jones,Gray Swan AI,Eliot Krzysztof Jones,Gray Swan AI,保障,决策规划,VLA,本文是首次系统性地研究VLA控制机器人的对抗攻击问题。不只是理论探讨，而是真正地测试这些模型是否能被文本攻击完全劫持。,"把原本用于大语言模型的“越狱攻击”技术迁移并适配到VLA模型中。
成功实现了对VLA系统的“完全控制权”，也就是：攻击者可以让机器人按照任意意图行事。",这篇论文探讨了将LLM的对抗攻击迁移到VLA中，实现了对VLA的劫持和越狱。,"adversarial attack, VLA",,https://arxiv.org/pdf/2506.03350,吴雄斌,决策规划,
